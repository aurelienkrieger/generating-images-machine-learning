# generating-images-machine-learning
Course about how to use generative models for AI art

## 1 – Enter the Latent Space
Learn about the history of AI & Machine Learning, understand the underlying technical concepts, discover the application fields to get inspired and generate your first images.

**Introductions**

- Introductions, Projects & Learning objectives
- Group introduction

**Lecture**

- Overview on Machine Learning & generative models
- Technical explanation on how does Stable Diffusion work
- Introduction to animation techniques

**Demos**

- Demo: Setup of software
- Demo: First images with Text to Image
- Demo: Import and experiment with various models
- Demo: Face restoration

## 2 – Image Generation
Improve your prompt engineering technique for image generation. Explore various models to experiment with a wide range of generated aesthetics.

**Lecture**

- Introduction to prompt engineering principles
- Introduction to negative prompting, CLIP interrogator
- How to apply a style with good prompts
- Introduction to inpainting, outpainting and upscaling

**Demos**

- Demo: Advanced prompting
- Demo: Inpainting basics
- Demo: Outpainting
- Demo: Upscaling
- Demo: Generating portraits
- Demo: Generating animals

## 3 – Image Compositing
Gain more control over your workflow and final composition. Explore the potential of neural style transfer and other techniques for concept art & visual prototyping.

**Lecture**

- Introduction to Image to Image
- Introduction to ControlNet, OpenPose, Depth, Canny, LineArt
- Introduction to Regional prompting

**Demos**

- Demo: Basic usage of Image to Image
- Demo: Testing ControlNet various processors for portraits
- Demo: Generating landscapes with ControlNet
- Demo: Using Sketch tool for colouring and image composition
- Demo: Using ControlNet for Sketch to Image
- Demo: Advanced compositing with ControlNet
- Demo: ControlNet QR pattern

## 4 – Video Generation
Discover how the techniques learnt previously can be applied for animated content generation

**Lecture**

- Introduction to Text to Video, Deforum
- Introduction to Video to Video
- Introduction to frame interpolation

**Demos**

- Demo: Using Deforum for pure Text to Video
- Demo: Video to Video
- Demo: Combine prompting and morphing for more control

## 5 – Machine Learning & Society
Learn how to train your own model to gain more control over your generative process. Investigate about the ethical dilemmas related to generative models. Debate with your peers and expand your critical thinking on the field.

**Lecture**

- Introduction to Machine Learning
- Introduction to training techniques with Stable Diffusion, Dreambooth, LoRA, LyCORIS, Embedding, Hypernetworks
- Real-world examples of AI ethical dilemmas

**Demos**
- Demo: Model training with Stable Diffusion
- Demo: Decrypting the technical setup and workflow of artists

**Activity**
- Group discussion: how does AI impact our lives?
- Brainstorm for student projects
- Students start working on their projects

## 6 – Final Presentations
Share your projects with your peers and reflect on progress as we discover each other's imagery. Reflect on the 6 weeks and share your new way of seeing things.
